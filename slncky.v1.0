#!/usr/bin/env python

import os
import sys
import argparse
import subprocess
import tempfile
from multiprocessing import Lock, Process, Queue
import time
from copy import deepcopy
import math

REALPATH = ''
ALIGNTRANSCRIPTS = ''
CONFIG = ''
LASTZ = 'lastz'
BEDTOOLS = 'bedtools'
FASTAFROMBED = 'fastaFromBed'
INTERSECTBED = 'intersectBed'
CLOSESTBED = 'closestBed'
LIFTOVER = 'liftOver'

def checkDependencies():
	#check bedtools version
	cmd = [BEDTOOLS, '--version']
	try:
		out = subprocess.check_output(cmd)
	except:
		sys.exit("ERROR: bedtools not installed! You must have bedtools v2.17.0 or higher in your path! Exiting...")

	out = out.split()
	version = out[1][1:].split(".")
	if int(version[0]) > 2 or int(version[1]) < 17:
		sys.exit("ERROR: The version of bedtools you have installed is too old. You must have bedtools v2.17.0 or higher in your path! Exiting...")

	#check lastz
	cmd = [LASTZ, '--version']
	try:
		p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE)
	except:
		sys.exit("ERROR: lastz not installed! You must have lastz in your path! Exiting...")

	out = p.stdout.read()
	out = out.split()
	if out[0].strip() != "lastz":
		sys.exit("ERROR: lastz not installed! You must have lastz in your path! Exiting...")

	#check lastz
	cmd = [LIFTOVER]
	try:
		p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE)
	except:
		sys.exit("ERROR: liftOver not installed! You must have liftOver in your path! Exiting...")

	out = p.stderr.read()
	out = out.split()
	if out[0].strip() != "liftOver":
		sys.exit("ERROR: liftOver not installed! You must have liftOver in your path! Exiting...")

def readAnnots(config_path, assembly):
	ANNOTS = {}

	##READ IN CONFIG FILE##
	try:
		config = open(config_path, 'r')
	except IOError:
		print "ERROR: cannot open ", config

	config_abspath = os.path.abspath(config_path)
	index = config_path.rfind("/")
	CONFIG_BASE = config_path[:index]

	flag = False
	for line in config.readlines():
		line = line.strip()
		if line == "" or line[0]=="#": continue
		
		if line[0] == ">" and line[1:] == assembly.strip():
			flag=True
		if line[0] == ">" and line[1:] != assembly.strip():
			flag=False

		if flag and line[0] != ">":
			line = line.split("=")
			file = line[1].strip()
			if line[0] != "ORTHOLOG": 
				if not os.path.isfile(file): 
					ogFile = file
					file = REALPATH+file
				if not os.path.isfile(file):
					file = CONFIG_BASE+ogFile
				if not os.path.isfile(file):
					print line[0]+" file "+ogFile+" does not exist! Please check your annotations.config file.  Exiting..."
					sys.exit(1)

			if line[0].strip() in ANNOTS:
				arr = ANNOTS[line[0].strip()]
				arr.append(file)
				ANNOTS[line[0].strip()] = arr
			else:
				ANNOTS[line[0].strip()] = [file]
	
	#CHECK ANNOTS
	if len(ANNOTS) == 0:
		print "WARNING: no annotations found for %s" % assembly
	else:
		if 'CODING' not in ANNOTS:
			print "WARNING: no coding file was supplied in annotations.config for %s. Cannot find overlap with coding genes." % assembly
		if 'GENOME_FA' not in ANNOTS:
			print "WARNING: no genome fasta file was supplied in annotations.config for %s.  Cannot blast to find duplications or matches to orthologous coding genes." %assembly

	return ANNOTS

def writeToTmp(dict):
	tempFd, tempPath = tempfile.mkstemp()

	temp = open(tempPath, 'w')
	for key,entry in dict.iteritems():
		temp.write(entry)
	temp.close()
	os.close(tempFd)

	return tempPath

def removeLncs(lncs, remove):
	counter = 0
	for item in remove:
		if item[0] in lncs: 
			del lncs[item[0]]
			counter += 1
	return lncs, counter

def splitToExons(lncs):
	
	lncExonFd, lncExonPath = tempfile.mkstemp()
	lncExon = os.fdopen(lncExonFd, 'w')

	lncSize = {}

	for lnc, line in lncs.iteritems():
		line = line.split()
		chr = line[0]
		start = int(line[1])
		name = line[3]
		score = 0
		strand = line[5]
		numBlocks = int(line[9].strip())
		blockSizes = line[10].split(",")
		blockStarts = line[11].split(",")
		
		size = 0
		for i in range(numBlocks):
			size += int(blockSizes[i])

			exonStart = start + int(blockStarts[i])
			exonEnd = exonStart + int(blockSizes[i])
			lncExon.write("%s\t%d\t%d\t%s\t%s\t%s\n" % (chr,exonStart,exonEnd,name,score, strand))
		lncSize[lnc] = size

	lncExon.close()

	return lncExonPath, lncSize

def removeSmallGenes(lncs):
	FILTER = []
	
	for lnc, entry in lncs.iteritems():
		entry = entry.split()
		if (int(entry[2]) - int(entry[1]) < 200): FILTER.append([lnc])
	
	newLncs, numRemoved = removeLncs(lncs, FILTER)
	return newLncs, FILTER, numRemoved

def removeOverlap(lncs, annots, args, min):
	FILTER = []
	lncExonPath, lncSize = splitToExons(lncs)

	cmd = INTERSECTBED
	for arg in args:
		cmd += " "+arg
	for file in annots:
		pairToOverlap = {}
		cmd += " -wao -a %s -b %s" % (lncExonPath, file)
		out = subprocess.check_output([cmd], shell=True)
		out = out.split("\n")	
		for line in out:
			if line.strip() == "": continue
			line= line.split()
			lnc = line[3].strip()
			gene = line[9].strip()
			if gene == ".": continue
			pair = lnc+"&"+gene
			overlap = int(line[18])
			if pair in pairToOverlap:
				newOverlap = pairToOverlap[pair] + overlap
				pairToOverlap[pair] = newOverlap
			else:
				pairToOverlap[pair] = overlap
		for pair, overlap in pairToOverlap.iteritems():
			pair = pair.split("&")
			lnc = pair[0]
			gene = pair[1]
			overlap = overlap*1.0 / lncSize[lnc]
			if overlap >= min:
				FILTER.append([lnc, gene, overlap, file])
	
	os.remove(lncExonPath)	
	FILTER.sort(key=lambda x: x[2], reverse=True)

	newLncs, numRemoved = removeLncs(lncs, FILTER)
	
	return newLncs, FILTER, numRemoved

def alignTranscripts(lncPath, fa, orthPath, orthFa, tmpPath, FILTER, min, null, keep):
	

	if BEDTOOLS[0:-9] != "" and LASTZ[0:-6] != "":
		cmd = [ALIGNTRANSCRIPTS, lncPath, fa, orthPath, orthFa, tmpPath, '--bedtools_path', BEDTOOLS[0:-8], '--lastz_path', LASTZ[0:-5]]
	elif BEDTOOLS[0:-8] != "":
		cmd = [ALIGNTRANSCRIPTS, lncPath, fa, orthPath, orthFa, tmpPath, '--bedtools_path', BEDTOOLS[0:-8]]
	elif LASTZ[0:-5] != "":
		cmd = [ALIGNTRANSCRIPTS, lncPath, fa, orthPath, orthFa, tmpPath, '--lastz_path', LASTZ[0:-5]]
	else:
		cmd = [ALIGNTRANSCRIPTS, lncPath, fa, orthPath, orthFa, tmpPath]
	
	ret = subprocess.call(cmd, stdout = null, stderr = null)
	if ret == 0:

		outFile = open(tmpPath+".alignment_identity.txt", 'r')
		out = outFile.readlines()
		outFile.close()

		exonID = 0
		seqID = 0
		for line in out:
			if line.strip() == "": continue
			line = line.split()
	
			if line[3] != "exonID" and float(line[3]) > min and float(line[3]) > exonID:
				exonID = float(line[3])
				seqID = float(line[4])
				category = line[8]
		if exonID > 0:		
			FILTER.put([line[1], line[2], exonID, seqID, category])
			if not keep:
				os.remove(tmpPath+".maf")
	
		os.remove(tmpPath+".alignment_identity.txt")
		

	FILTER.put(0)

	#os.remove(lncPath)
	#os.remove(orthPath)
	

def blastToOrtholog(lncs, annots, orth_annots, blastTo, min, n, alignments_dir):
	##TODO: add code to make bed file, orth bed file, and maf.tar.gz file
	##if blastTo == coding and website is on, make vis files
	##always make files for noncoding

	queue = Queue()
	FILTER = []
	FLUSHED = 0
	lncFile = writeToTmp(lncs)
	
	liftOverFd, liftOverPath = tempfile.mkstemp()
	unmappedPath = liftOverPath+".unmapped"


	#liftover
	cmd = "cut -f1-4 %s | %s -minMatch=0.1 /dev/stdin %s %s %s" % (lncFile, LIFTOVER, annots["LIFTOVER"][0], liftOverPath, unmappedPath)
	null = open("/dev/null", 'w')
	proc = subprocess.check_call([cmd],shell=True, stdout=null, stderr=null)
	null.close()
	os.remove(lncFile)

	removed = 0
	processes = []
	null = open("/dev/null", 'w')
	for file in orth_annots[blastTo]:
		numAligned = 0
		cmd = [INTERSECTBED, '-wa', '-wb', '-a', liftOverPath, '-b', file]
		#print cmd
		out = subprocess.check_output(cmd)
		out = out.split("\n")
		for line in out:
			numAligned += 1
			if line.strip() == "": continue
			line= line.split()
			lnc = line[3].strip()
			lncBed = lncs[lnc]
			
			overlapBed = line[4]
			for i in range(5, len(line)):
				overlapBed += "\t"+line[i]
			lncFd, lncPath = tempfile.mkstemp()
			lncFile = os.fdopen(lncFd, 'w')
			lncFile.write(lncBed)
			lncFile.close()

			orthPath = lncPath+".orth"
			orthFile = open(orthPath, 'w')
			orthFile.write(overlapBed)
			orthFile.close()

			if alignments_dir == "":
				keep = False
				tmpOutPath = lncPath+".maf"
			else:
				keep = True
				tmpOutPath = alignments_dir+lnc+"-"+overlapBed.split()[3].strip()
			
			p = Process(target=alignTranscripts, args=(lncPath, annots["GENOME_FA"][0], orthPath, orth_annots["GENOME_FA"][0], tmpOutPath, queue, min, null, keep))
			p.start()
			#pids[p.pid] = [lncFile, file, gene, overlap]

			processes.append(p)
			print "\r    aligning %d / %d genes to ortholog in %s" % (numAligned, len(out), file),
			sys.stdout.flush()
			while True:
				counter = 0
				
				for p in processes:
					if p.is_alive(): 
						counter += 1
				if counter < n: break
				else: 
					queue.put('STOP')
					for item in iter(queue.get, 'STOP'):
						if item == 0: FLUSHED += 1
						else: FILTER.append(item)
					time.sleep(1)
	null.close()	
	while FLUSHED < len(processes):
		queue.put('STOP')
		for item in iter(queue.get, 'STOP'):
			if item == 0: FLUSHED += 1
			else: FILTER.append(item)


	for p in processes:
		p.join()

	os.remove(liftOverPath)
	os.remove(unmappedPath)

	#newLncs, numRemoved = removeLncs(lncs, FILTER)

	return FILTER

def readMaf(maf, FILTER, cov_min, id_min):
	selfBlast = {}
	
	for i in range(16, len(maf)):
		line = maf[i]
		if line == "": continue
		if i % 8 == 0:
			identity = line.split(" ")[2].strip()[1:-2]
		if i % 8 == 1:
			coverage = line.split(" ")[2].strip()[1:-2]
		if i % 8 == 2:
			continuity = line.split(" ")[2].strip()[1:-2]
		if i % 8 == 5:
			name = line.split(" ")[1].strip()
		if i % 8 == 6:
			queryName = line.split(" ")[1].strip()
			if name.strip() != queryName.strip() and float(identity) >= cov_min*100 and float(coverage) >= id_min*100:
				pair = name.strip()+"&"+queryName.strip()
				if pair in selfBlast:
					if float(identity) > selfBlast[pair][0]:
						selfBlast[pair] = [float(identity), float(coverage)]
				else:
					selfBlast[pair] = [float(identity), float(coverage)]

	for pair, id in selfBlast.iteritems():
		pair = pair.split("&")
		FILTER.put([pair[0], pair[1], id[0], id[1]])


	del selfBlast

def selfBlastOneLnc(curLnc, lncs, FILTER, cov_min, id_min, tmpPath):
	#cmd = "%s %s %s --format=maf+" % (LASTZ, curLnc, lncs)
	#cmd = [LASTZ, curLnc, lncs, '--format=maf+']
	cmd = [LASTZ, curLnc, lncs, '--format=maf+', '--output=%s' % tmpPath]
	subprocess.call(cmd)

	file = open(tmpPath, 'r')
	out = file.readlines()
	file.close()
	readMaf(out, FILTER, cov_min, id_min)

	#cmd = ['rm', '-f', curLnc, lncs, tmpPath]
	#subprocess.check_call(cmd)
	os.remove(curLnc)
	os.remove(lncs)
	os.remove(tmpPath)

	FILTER.put(0)

def selfBlast(lncs, annots, cov_min, id_min, n):
	queue = Queue()

	#for every lnc
		#add blastOneLnc process
	processes = []
	numAligned = 0
	lncFile = writeToTmp(lncs)
	
	FILTER = []
	FLUSHED = 0
	
	for lnc, entry in lncs.iteritems():
		
		#make target fasta
		curLnc = {}
		curLnc[lnc] = entry
		curLncFile = writeToTmp(curLnc)
		curLncFaPath = curLncFile+".fa"

		cmd = [FASTAFROMBED, '-fi', annots["GENOME_FA"][0], '-bed', curLncFile, '-fo', curLncFaPath, '-split', '-name']
		subprocess.check_call(cmd)
		
		#make query fasta
		queryLncBedPath = curLncFile+".query.bed"
		#cmd = "%s -v -a %s -b %s > %s" % (INTERSECTBED, lncFile, curLncFile, queryLncBedPath)
		cmd = [INTERSECTBED, '-v', '-a', lncFile, '-b', curLncFile] 
		out = subprocess.check_output(cmd)
		queryLncBed = open(queryLncBedPath, 'w')
		queryLncBed.write(out)
		queryLncBed.close()

		queryLncFaPath = curLncFile+".query.fa"
		cmd = [FASTAFROMBED, '-fi', annots["GENOME_FA"][0], '-bed', queryLncBedPath, '-fo', queryLncFaPath, '-split', '-name']
		subprocess.call(cmd)
		
		mafBedPath = curLncFile+".maf"
		
		os.remove(queryLncBedPath)
		os.remove(curLncFile)
		
		p = Process(target=selfBlastOneLnc, args=(curLncFaPath, queryLncFaPath, queue, cov_min, id_min, mafBedPath))
		numAligned += 1
		p.start()
		processes.append(p)
		
		print "\r    self-blasting %d / %d genes" % (numAligned, len(lncs)),
		sys.stdout.flush()
		while True:
			counter = 0
			for p in processes:
				if p.is_alive(): counter += 1
			if counter < n*4: break
			else: 
				queue.put('STOP')
				for item in iter(queue.get, 'STOP'):
					if item == 0: FLUSHED += 1
					else: FILTER.append(item)
				time.sleep(1)
	

	while (FLUSHED < len(processes)):
		queue.put('STOP')
		for item in iter(queue.get, 'STOP'):
			if item == 0: FLUSHED += 1
			else: FILTER.append(item)

	for p in processes:
		p.join()

	newLncs, numRemoved = removeLncs(lncs, FILTER)
	
	return newLncs, FILTER, numRemoved
	#return lncs, FILTER, 0

def repeatFilter(lncs, annots, repeat_min):
	lncExonPath, lncSize = splitToExons(lncs)

	cmd = "%s -wo -a %s -b %s" % (INTERSECTBED, lncExonPath, annots["REPEAT_MASKER"][0])
	out = subprocess.check_output([cmd], shell=True)
	out = out.split("\n")
	
	lncOverlap = {}
	for line in out:
		if line.strip() == "": continue
		line = line.split()
		lnc = line[3].strip()
		overlap = int(line[18])
		if lnc in lncOverlap:
			a = lncOverlap[lnc]
			lncOverlap[lnc] = a + overlap
		else: lncOverlap[lnc] = overlap
	
	os.remove(lncExonPath)
	FILTER = []
	REPEAT = []

	for lnc, overlap in lncOverlap.iteritems():
		percent = overlap*1.0 / lncSize[lnc]
		if (percent > repeat_min):
			FILTER.append([lnc, percent])
		REPEAT.append([lnc, percent])
	#newLncs, numRemoved = removeLncs(lncs, FILTER)
	return lncs, FILTER, 0, REPEAT

def writeOverlappingTranscripts(TEMPLATE_PATH, out, sense_min, antisense_min, ogLncs, SENSE_FILTER, ANTISENSE_FILTER, SENSE_MAPPED_CODING_FILTER, ANTISENSE_MAPPED_CODING_FILTER):
	pre = out+"_html/"
	template_overlapCoding = open(TEMPLATE_PATH+"overlapCoding.html", 'r')
	html = open(pre+"overlapCoding.html", 'w')
	
	for line in template_overlapCoding.readlines():
		if line.startswith("PARAMETERS"):
			line = line.replace("ANTISENSE_MIN", str(antisense_min))
			line = line.replace("SENSE_MIN", str(sense_min))
			line = line.replace("PARAMETERS", "")

			html.write(line)
		elif line.startswith("FILTERED"):
			lncs = set()
			for x in SENSE_FILTER: lncs.add(x[0])
			for x in ANTISENSE_FILTER: lncs.add(x[0])
			for x in SENSE_MAPPED_CODING_FILTER: lncs.add(x[0])
			for x in ANTISENSE_MAPPED_CODING_FILTER: lncs.add(x[0])
			
			line = line.replace("NUM_FILTERED", str(len(lncs)))
			line = line.replace("FILTERED", "")
			html.write(line)

		elif line.startswith("CUSTOM"):
			line = line.replace("CUSTOM_PATH", pre+out+".overlap.bed")
			line = line.replace("CUSTOM", "")
			html.write(line)
		elif line.startswith("OPTIONS"):
			html.write("<option value=\"none\" style=\"font-weight: bold;\">OVERLAPS CODING</option>")
			for x in SENSE_FILTER:
				lncEntry = ogLncs[x[0]].split("\t")
				chr = lncEntry[0]
				start = lncEntry[1]
				end = lncEntry[2]
				html.write("<option value=\"http://genome.ucsc.edu/cgi-bin/hgTracks?db=mm9&position=%s:%s-%s\">%s - %.1f%% sense</option>\n" % (chr, start, end, x[0], x[2]*100.0))
			for x in ANTISENSE_FILTER:
				lncEntry = ogLncs[x[0]].split("\t")
				chr = lncEntry[0]
				start = lncEntry[1]
				end = lncEntry[2]
				html.write("<option value=\"http://genome.ucsc.edu/cgi-bin/hgTracks?db=mm9&position=%s:%s-%s\">%s - %.1f%% antisense</option>\n" % (chr, start, end, x[0], x[2]*100.0))
			
			html.write("<option value=\"none\" style=\"font-weight: bold;\">OVERLAPS MAPPED CODING</option>")
			for x in SENSE_MAPPED_CODING_FILTER:
				lncEntry = ogLncs[x[0]].split("\t")
				chr = lncEntry[0]
				start = lncEntry[1]
				end = lncEntry[2]
				html.write("<option value=\"http://genome.ucsc.edu/cgi-bin/hgTracks?db=mm9&position=%s:%s-%s\">%s - %.1f%% sense</option>\n" % (chr, start, end, x[0], x[2]*100.0))
			for x in ANTISENSE_MAPPED_CODING_FILTER:
				lncEntry = ogLncs[x[0]].split("\t")
				chr = lncEntry[0]
				start = lncEntry[1]
				end = lncEntry[2]
				html.write("<option value=\"http://genome.ucsc.edu/cgi-bin/hgTracks?db=mm9&position=%s:%s-%s\">%s - %.1f%% antisense</option>\n" % (chr, start, end, x[0], x[2]*100.0))
		else:
			html.write(line)

def writeCodingBlast(TEMPLATE_PATH, out, coding_blast_min, CODING_BLAST_FILTER):
	pre = out+"_html/"

	template_codingBlast = open(TEMPLATE_PATH+"blastCoding.html", 'r')
	html = open(pre+"blastCoding.html", 'w')
	
	for line in template_codingBlast.readlines():
		if line.startswith("PARAMETERS"):
			line = line.replace("PARAMETERS", "")
			line = line.replace("CODING_BLAST_MIN", str(coding_blast_min))
		elif line.startswith("FILTERED"):
			lncs = set()
			for x in CODING_BLAST_FILTER: lncs.add(x[0])
			line = line.replace("NUM_GENES", str(len(lncs)))
			line = line.replace("TAR", out+"_html/"+out+"_alignToCoding.tar.gz")
			line = line.replace("FILTERED", "")

		html.write(line)

def makeClusters(SELF_BLAST_FILTER):
	#create clusters
	sets = []
	pairsToId = {}

	for x in SELF_BLAST_FILTER:
		pair = x[0]+"&"+x[1]
		id = float(x[3])
		if (pair in pairsToId and id > pairsToId[pair]) or (pair not in pairsToId):
			pairsToId[pair] = id
		
		newSet = set()
		newSet.add(x[0])
		newSet.add(x[1])
		sets.append(newSet)
	
	merged = True
	while merged:
		merged = False
		results = []
		while sets:
			common, rest = sets[0], sets[1:]
			sets = []
			for x in rest:
				if x.isdisjoint(common):
					sets.append(x)
				else:
					merged = True
					common |= x
			results.append(common)
		sets = results
	return sets, pairsToId

def writeJson(out, sets, pairsToId):
	pre = out+"_html/"
	lncToNum = {}
	#write json

	json = open(pre+out+".duplications.json", 'w')
	json.write("{\"nodes\": [")
	
	counter = -1
	for i in range(len(sets)):
		x = sets[i]
		for lnc in x:
			counter += 1
			lncToNum[lnc] = counter
			if counter == 0:
				json.write("{\"name\": \"%s\", \"group\": %d}" % (lnc, i+1))
			else:
				json.write(", {\"name\": \"%s\", \"group\": %d}" % (lnc, i+1))
	
	json.write("], ")

	json.write("\"links\":[")
	
	counter = 0
	for pair, id in pairsToId.iteritems():
		counter += 1
		pair = pair.split("&")
		source = lncToNum[pair[0]]
		target = lncToNum[pair[1]]
		if counter == 1: json.write("{\"source\": %d, \"target\": %d, \"value\": %d}" % (source, target, int(round(id))))
		else:  json.write(", {\"source\": %d, \"target\": %d, \"value\": %d}" % (source, target, int(round(id))))

	for lnc, num in lncToNum.iteritems():
		json.write(", {\"source\": %d, \"target\": %d, \"value\": 100}" % (num, num))
	json.write("]}")

def writeDuplications(TEMPLATE_PATH, out, SELF_BLAST_FILTER, id_min):
	
	pre = out+"_html/"
	template_codingBlast = open(TEMPLATE_PATH+"selfBlast.html", 'r')
	html = open(pre+"selfBlast.html", 'w')
	
	#genea, geneb, coverage, id, continuity
	sets, pairsToId = makeClusters(SELF_BLAST_FILTER)
	writeJson(out, sets, pairsToId)
	
	for line in template_codingBlast.readlines():
		if line.startswith("PARAMETERS"):
			line = line.replace("PARAMETERS", "")
			line = line.replace("SELFBLAST_ID_MIN", str(id_min))
		elif line.startswith("FILTERED"):
			lncs = set()
			for x in SELF_BLAST_FILTER: lncs.add(x[0])
			line = line.replace("NUM_FILTERED", str(len(lncs)))
			line = line.replace("FILTERED", "")
			line = line.replace("ID", str(id_min*100))
		elif line.startswith("JSON"):
			line = line.replace("JSON_FILE", out+".duplications.json")
			line = line.replace("JSON", "")

		html.write(line)	


def writeHist(out, REPEAT_CONTENT, cleanLncs):
	pre = out+"_html/"
	#make histogram
	before_hist = [0]*20

	total = 0
	for x in REPEAT_CONTENT:
		total += 1
		index = int(math.floor(x[1] * 20))
		if index>= 20: index = 19
		before_hist[index] = before_hist[index]+1
	
	after_hist = [0]*20

	after_total = 0
	for x in REPEAT_CONTENT:
		lnc = x[0]
		content = x[1]
		if lnc in cleanLncs:
			after_total += 1
			index = int(math.floor(content*20))
			if index >=20: index = 19
			after_hist[index] = after_hist[index] + 1
	
	repeat = open(pre+out+".repeat_histogram.txt", 'w')
	repeat.write("letter\tfrequency_b\tfrequency_a\n")
	for i in range(len(before_hist)):
		repeat.write("%d-%d%%\t%.2f\t%.2f\n" %(i*5, (i*5)+5, (before_hist[i]*1.0) / total, after_hist[i]*1.0 / after_total))


def writeRepeat(TEMPLATE_PATH, out, REPEAT_FILTER, REPEAT_CONTENT, repeat_min, cleanLncs):
	
	pre = out+"_html/"
	template_repeatContent = open(TEMPLATE_PATH+"repeatContent.html", 'r')
	html = open(pre+"repeatContent.html", 'w')
	
	writeHist(out, REPEAT_CONTENT, cleanLncs)
	
	for line in template_repeatContent.readlines():
		if line.startswith("PARAMETERS"):
			line = line.replace("REPEAT_MIN", str(repeat_min))
			line = line.replace("PARAMETERS", "")
			html.write(line)
		elif line.startswith("FILTERED"):
			line = line.replace("REPEAT_MIN", str(repeat_min*100))
			line = line.replace("NUM_FILTERED", str(len(REPEAT_FILTER)))
			line = line.replace("FILTERED", "")
			html.write(line)
			html.write("<ul>\n")
			for x in REPEAT_FILTER:
				html.write("<li>%s - %.1f%%</li>\n" % (x[0], x[1]*100))
			html.write("</ul>\n")
		elif line.startswith("TXT"):
			line = line.replace("TXT_FILE", out+".repeat_histogram.txt")
			line = line.replace("TXT", "")
			html.write(line)
		else:
			html.write(line)

def writeOrth(TEMPLATE_PATH, out, noncoding_blast_min, ORTHOLOGS):
	pre = out+"_html/"

	template_orthologs = open(TEMPLATE_PATH+"orthologs.html", 'r')
	html = open(pre+"orthologs.html", 'w')
	
	for line in template_orthologs.readlines():
		if line.startswith("PARAMETERS"):
			line = line.replace("PARAMETERS", "")
			line = line.replace("NONCODING_BLAST_MIN", str(noncoding_blast_min))
		elif line.startswith("ORTHOLOGS"):
			lncs = set()
			for x in ORTHOLOGS: lncs.add(x[0])
			line = line.replace("NUM_GENES", str(len(lncs)))
			line = line.replace("ORTHOLOGS", "")
			line = line.replace("TAR", out+"_alignments.tar.gz")
		html.write(line)

def writeWebsite(ANNOTS, out, ogLncs, sense_min, antisense_min, coding_blast_min, SENSE_FILTER, ANTISENSE_FILTER, SENSE_MAPPED_CODING_FILTER, ANTISENSE_MAPPED_CODING_FILTER, CODING_BLAST_FILTER, SELF_BLAST_FILTER, id_min, REPEAT_FILTER, REPEAT_CONTENT, repeat_min, cleanLncs):

	pre = out+"_html/"
	TEMPLATE_PATH = REALPATH+"/html_templates/"
	template_css = TEMPLATE_PATH+"/stylesheet.css"
	
	#cp template sheet over
	cmd = ['cp', template_css, pre]
	subprocess.check_call(cmd)
	
	#write index
	template_index = open(TEMPLATE_PATH+"index.html", 'r')
	index = open(pre+"index.html", 'w')

	for line in template_index.readlines():
		if line.startswith("FILTERHEADER"):
			line = line.replace("FILTERHEADER", "")
			index.write(line)
		elif line.startswith("FILTER1"):
			if "CODING" in ANNOTS or "MAPPED_CODING" in ANNOTS:
				line = line.replace("FILTER1", "")
				index.write(line)
				writeOverlappingTranscripts(TEMPLATE_PATH, out, sense_min, antisense_min, ogLncs, SENSE_FILTER, ANTISENSE_FILTER, SENSE_MAPPED_CODING_FILTER, ANTISENSE_MAPPED_CODING_FILTER)
		elif line.startswith("FILTER2"):
			if len(CODING_BLAST_FILTER)>0:
				line = line.replace("FILTER2", "")
				index.write(line)
				writeCodingBlast(TEMPLATE_PATH, out, coding_blast_min, CODING_BLAST_FILTER)
		elif line.startswith("FILTER3"):
			if "GENOME_FA" in ANNOTS:
				line = line.replace("FILTER3", "")
				index.write(line)
				writeDuplications(TEMPLATE_PATH, out, SELF_BLAST_FILTER, id_min)
		elif line.startswith("FILTER4"):
			if "REPEAT_MASKER" in ANNOTS:
				line = line.replace("FILTER4", "")
				index.write(line)
				writeRepeat(TEMPLATE_PATH, out, REPEAT_FILTER, REPEAT_CONTENT, repeat_min, cleanLncs)
		elif not line.startswith("NOFILTERHEADER"): 
			index.write(line)



def writeNoFilterWebsite(out):

	pre = out+"_html/"
	TEMPLATE_PATH = REALPATH+"/html_templates/"
	template_css = TEMPLATE_PATH+"/stylesheet.css"
	
	#cp template sheet over
	cmd = ['cp', template_css, pre]
	subprocess.check_call(cmd)
	
	#write index
	template_index = open(TEMPLATE_PATH+"index.html", 'r')
	index = open(pre+"index.html", 'w')

	for line in template_index.readlines():
		if line.startswith("NOFILTERHEADER"):
			line = line.replace("NOFILTERHEADER", "")
			index.write(line)
		elif not line.startswith("FILTER"):
			index.write(line)


def writeOrthSearch(out, noncoding_blast_min, ORTHOLOGS):

	pre = out+"_html/"
	index = open(pre+"index.html", 'r')
	new_index = open(pre+"tmp", 'w')
	TEMPLATE_PATH = REALPATH+"/html_templates/"
	
	for line in index.readlines():
		if line.startswith("ORTH"):
			line = line.replace("ORTH", "")
			new_index.write(line)
			writeOrth(TEMPLATE_PATH, out, noncoding_blast_min, ORTHOLOGS)
		elif not line.startswith("NOORTH"):
			new_index.write(line)
	
	cmd = ['mv', pre+"tmp", pre+"index.html"]
	subprocess.call(cmd)

def writeNoOrthSearch(out):

	pre = out+"_html/"
	index = open(pre+"index.html", 'r')
	new_index = open(pre+"tmp", 'w')
	TEMPLATE_PATH = REALPATH+"/html_templates/"
	
	for line in index.readlines():
		if line.startswith("NOORTH"):
			line = line.replace("NOORTH", "")
			new_index.write(line)
		elif not line.startswith("ORTH"):
			new_index.write(line)
	
	cmd = ['mv', pre+"tmp", pre+"index.html"]
	subprocess.call(cmd)

def categorizeLncsByAnnots(lncs, ORTHOLOGS, ANNOTS):
	if "MIRNA" not in ANNOTS or "SNORNA" not in ANNOTS:
		print "WARNING!: miRNA and snoRNA annotations not found for lnc categorization"
	lncToCategory = {}
	for entry in ORTHOLOGS:
		category = ""
		lnc = entry[0]
		if lnc in lncToCategory:
			category = lncToCategory[lnc]
		else:
			curLncFile = writeToTmp({lnc: lncs[lnc]})
			#check if snorna host
			if "SNORNA" in ANNOTS:
				cmd =[INTERSECTBED, '-a', curLncFile, '-b', ANNOTS["SNORNA"][0]]
				out = subprocess.check_output(cmd)
				if out.strip() != "":
					category = "sno_host"
					lncToCategory[lnc] = "sno_host"
			#check if mirna host
			if category == "" and  "MIRNA" in ANNOTS:
				cmd =[INTERSECTBED, '-a', curLncFile, '-b', ANNOTS["MIRNA"][0]]
				out = subprocess.check_output(cmd)
				if out != "":
					category = "mir_host"
					lncToCategory[lnc] = "mir_host"
			#check if divergent
			if category == "":
				for file in ANNOTS["CODING"]:
					if category != "": break
					cmd = [CLOSESTBED, '-id', '-D', 'a', '-S', '-a', curLncFile, '-b', file]
					out = subprocess.check_output(cmd)
					out = out.split("\n")
					for line in out:
						if line.strip() == "": break
						if category != "": break
						line = line.split("\t")
						if line[5] == "+":
							lncTSS = int(line[1])
						else:
							lncTSS = int(line[2])
						if line[17] == "+":
							codingTSS = int(line[13])
						else:
							codingTSS = int(line[14])
						if abs(lncTSS - codingTSS) <=500:
							category = "divergent"
							lncToCategory[lnc] = "divergent"
			#if none of above and exonId > 10%: intergenic
			if category == "":
				maxExonId = float(entry[2])
				for x in ORTHOLOGS:
					if x[0] == lnc and float(x[2]) > maxExonId: maxExonId = float(x[2])
				
				if maxExonId >= 0.1: category = "intergenic"
				else: category = "intergenic (bad_alignment)"
				lncToCategory[lnc] = category

			#cleanup
			cmd = ['rm', curLncFile]
			subprocess.call(cmd)
		entry.append(category)

def geneSymbol(ogLncs, ORTHOLOGS, ANNOTS, ORTH_ANNOTS):
	lncToGeneSymbol = {}
	GeneSymbol = {}
	OrthGeneSymbol = {}

	if "GENESYMBOL" in ANNOTS:
	#load gene symbol file into dict
		genesymbol = open(ANNOTS["GENESYMBOL"][0], 'r').readlines()
		for line in genesymbol:
			line = line.split()
			GeneSymbol[line[0].strip()] = line[1].strip()

	if "GENESYMBOL" in ORTH_ANNOTS:
	#load gene symbol file into dict
		genesymbol = open(ORTH_ANNOTS["GENESYMBOL"][0], 'r').readlines()
		for line in genesymbol:
			line = line.split()
			OrthGeneSymbol[line[0].strip()] = line[1].strip()

	for entry in ORTHOLOGS:
		lncGeneSymbol = "Unannotated"
		orthGeneSymbol = "Unannotated"	

		lnc = entry[0]
		if lnc in lncToGeneSymbol:
			lncGeneSymbol = lncToGeneSymbol[lnc]
		elif "GENESYMBOL" in ANNOTS:
			curLncFile = writeToTmp({lnc: ogLncs[lnc]})
			maxOverlap = 0
			#for every noncoding file
			for file in ANNOTS["NONCODING"]:
				#intersect lnc with noncoding
				cmd = [INTERSECTBED, '-split', '-s', '-wo', '-a', curLncFile, '-b', file]
				out = subprocess.check_output(cmd)
				#pick best intersecting and get gene symbol
				out = out.split("\n")
				for line in out:
					if line.strip() == "": continue
					line = line.split()
					overlap = int(line[len(line)-1])
					if overlap > maxOverlap and line[15].strip() in GeneSymbol:
						lncGeneSymbol = GeneSymbol[line[15].strip()]
						maxOverlap = overlap

		ortholog = entry[1]
		if ortholog in OrthGeneSymbol:
			orthGeneSymbol = OrthGeneSymbol[ortholog]

		entry.append(lncGeneSymbol)
		entry.append(orthGeneSymbol)

def main():
	parser = argparse.ArgumentParser(description='Filter transcripts for bona fide lncRNAs and searches for orthologs')
	parser.add_argument('bedfile', type=str, help='bed12 file of transcripts')
	parser.add_argument('assembly', type=str, help='assembly')
	parser.add_argument('out_prefix', type=str, help='out_prefix')
	parser.add_argument('--overwrite', '-ow', action='store_true', help='forces overwrite of out_prefix.bed')
	parser.add_argument('--config', '-c', type=str, help='path to assembly.config file. default uses config file in same directory as slncky')
	parser.add_argument('--sense_min', type=float, help='min exonic overlap to filter out sense overlapping transcript, default = 0', default = 0)
	parser.add_argument('--antisense_min', type=float, help='min exonic overlap to filter out antisense overlapping transcript, default = 0.3', default=0.3)
	parser.add_argument('--coding_blast_min', type=float, help='min exonic identity to filter out transcript that blasts to orthologous coding gene. default = 0.1', default=0.1)
	parser.add_argument('--selfblast_coverage_min', '-sbc', type=float, help='min coverage when blasting for duplications within transcript. default=0.5', default=0.5)
	parser.add_argument('--selfblast_identity_min', '-sbi', type=float, help='min identity when blasting for duplications within transcript. default=0.5', default=0.5)
	parser.add_argument('--repeat_min', '-r', type=float, help='min repeat content. default = 0.97', default=0.97)
	parser.add_argument('--noncoding_blast_min', type=float, help='min exonic identity to filter out transcript that blasts to orthologous noncoding gene. default=0', default=0.0)
	parser.add_argument('--threads', '-n', type=int, help='number of threads. default = 5', default=5)
	parser.add_argument('--bedtools_path', type=str, help='path to bedtools')
	parser.add_argument('--liftover_path', type=str, help='path to liftOver')
	parser.add_argument('--lastz_path', type=str, help='path to lastz')
	parser.add_argument('--no_filter', action='store_true', help='flag if you don\'t want lncs to be filtered before searching for ortholog')
	parser.add_argument('--no_orth_search', action='store_true', help='flag if you only want to filter lncs but don\'t want to search for orthologs')
	parser.add_argument('--no_web', action='store_true', help='flag if you don\'t want website written visualizing transcripts that were filtered out')
	args = parser.parse_args()
	
	global REALPATH
	global ALIGNTRANSCRIPTS
	REALPATH = os.path.realpath(__file__)[0:-11]
	ALIGNTRANSCRIPTS = REALPATH+"alignTranscripts"
	if args.config is None: args.config = REALPATH+"annotations.config"

	print args.config

	if args.bedtools_path is not None:
		global FASTAFROMBED
		global INTERSECTBED
		global BEDTOOLS
		FASTAFROMBED = args.bedtools_path+"/fastaFromBed"
		INTERSECTBED = args.bedtools_path+"/intersectBed"
		CLOSESTBED = args.bedtools_path+"/closestBed"
		BEDTOOLS = args.bedtools_path+"/bedtools"
	if args.liftover_path is not None:
		global LIFTOVER
		LIFTOVER = args.liftover_path+"/liftOver"
	if args.lastz_path is not None:
		global LASTZ
		LASTZ = args.lastz_path+"/lastz"

	checkDependencies()

	#READ IN ANNOTATIONS#
	print "Loading annotations for %s" % args.assembly

	ANNOTS = readAnnots(args.config, args.assembly)

	if "ORTHOLOG" in ANNOTS: 
		#check for liftover file
		if "LIFTOVER" not in ANNOTS:
			print "WARNING: Ortholog was specified for %s but NOT a liftover file.  No ortholog analysis will be carried out!" % args.assembly

		print "Loading ortholog annotations for %s" % ANNOTS["ORTHOLOG"][0]
		ORTH_ANNOTS = readAnnots(args.config, ANNOTS["ORTHOLOG"][0])

	#READ IN LNCS#
	lncs = {}

	bed = open(args.bedfile, 'r')
	for line in bed.readlines():
		splitline = line.split()
		lncs[splitline[3].strip()] = line
	bed.close()
	ogLncs = deepcopy(lncs)
	
	print "\nStarting with %d transcripts" % len(lncs)

	if not args.no_filter:
	
		if os.path.isfile(args.out_prefix+".bed") and not args.overwrite:
			print "%s.bed already exists! Please choose a different out_prefix." % args.out_prefix
			sys.exit(1)

		print "Removing..."
		#INITIALIZE FILTERS
		SMALL_FILTER = []
		SENSE_FILTER = []
		ANTISENSE_FILTER = []
		WITHIN_FILTER = []
		SENSE_MAPPED_CODING_FILTER = []
		ANTISENSE_MAPPED_CODING_FILTER = []
		CODING_BLAST_FILTER = []
		SELF_BLAST_FILTER = []
		REPEAT_FILTER = []
		REPEAT_CONTENT = []
		#INTERSECT WITH CODING GENES
		if "CODING" in ANNOTS:
			#lncs, SENSE_FILTER, numRemoved = removeSenseOverlap(lncs, ANNOTS)
			
			lncs, SENSE_FILTER, numRemoved = removeOverlap(lncs, ANNOTS["CODING"], ['-s', '-split'], args.sense_min)

			print "        ... %d transcripts that overlap >%d%% with coding transcript (sense)" % (numRemoved, int(args.sense_min*100))

			#lncs, ANTISENSE_FILTER, numRemoved = removeAntisenseOverlap(lncs, ANNOTS)
			lncs, ANTISENSE_FILTER, numRemoved = removeOverlap(lncs, ANNOTS["CODING"], ['-S', '-split'], args.antisense_min)
			print "        ... %d transcripts that overlap >%d%% with coding transcript (antisense)" % (numRemoved, int(args.antisense_min*100))
			
			lncs, WITHIN_FILTER, numRemoved = removeOverlap(lncs, ANNOTS["CODING"], [], 1)
			print "        ... %d transcripts that fall within coding transcript" % (numRemoved)


		if "MAPPED_CODING" in ANNOTS:
			lncs, SENSE_MAPPED_CODING_FILTER, numRemoved = removeOverlap(lncs, ANNOTS["MAPPED_CODING"], ['-s', '-split'], args.sense_min)
			print "        ... %d transcripts that overlap >%d%% with mapped coding transcript (sense)" % (numRemoved, int(args.sense_min*100))
		
			lncs, ANTISENSE_MAPPED_CODING_FILTER, numRemoved = removeOverlap(lncs, ANNOTS["MAPPED_CODING"], ['-S', '-split'], args.antisense_min)
			print "        ... %d transcripts that overlap >%d%% with mapped coding transcript (antisense)" % (numRemoved, int(args.antisense_min*100))


		lncs, SMALL_FILTER, numRemoved = removeSmallGenes(lncs)
		print "        ... %d transcripts shorter than 200bp" % numRemoved

		#REPEAT_CONTENT
		if "REPEAT_MASKER" in ANNOTS:
			repeatLncs, REPEAT_FILTER, numRemoved, REPEAT_CONTENT = repeatFilter(ogLncs, ANNOTS, args.repeat_min)
			lncs, numRemoved = removeLncs(lncs, REPEAT_FILTER)
			print "        ... %d transcripts with >97%% repeat content" % numRemoved


		#BLAST TO CODING ORTHOLOGS
		#make directory for coding
		coding_alignments_dir = ""
		if not args.no_web:
			coding_alignments_dir = args.out_prefix + "_alignToCoding/"
			if not os.path.exists(coding_alignments_dir):
				os.mkdir(coding_alignments_dir)

		if "ORTHOLOG" in ANNOTS and "LIFTOVER" in ANNOTS and "GENOME_FA" in ANNOTS and "GENOME_FA" in ORTH_ANNOTS and "CODING" in ORTH_ANNOTS:
			CODING_BLAST_FILTER = blastToOrtholog(lncs, ANNOTS, ORTH_ANNOTS, "CODING", args.coding_blast_min, args.threads, coding_alignments_dir)
			lncs, numRemoved = removeLncs(lncs, CODING_BLAST_FILTER)
			print "\r        ... %d transcripts that blast >%d%% to ortholog coding transcript                                                                   " % (numRemoved, int(args.coding_blast_min*100))
		
		#SELF-BLAST TO FIND DUPLICATIONS
		if "GENOME_FA" in ANNOTS:
			lncs, SELF_BLAST_FILTER, numRemoved = selfBlast(lncs, ANNOTS, args.selfblast_coverage_min, args.selfblast_identity_min, args.threads)
			#lncs, numRemoved = removeLncs(lncs, SELF_BLAST_FILTER) 
			print "\r        ... %d transcripts that blast >%d%% to another transcript in input file                                                             " % (numRemoved, int(args.selfblast_identity_min*100))
		
		#WRITE FILTERED DATA
		
		finalLncs = open(args.out_prefix+".bed", 'w')
		for lnc, line in lncs.iteritems():
			finalLncs.write(line)
		finalLncs.close()

		#WRITE FILTERED TXT
		
		if not args.no_web:

			pre = args.out_prefix+"_html/"
			if os.path.exists(pre):
				print pre+" already exists. overwriting..."
				cmd = ['rm', '-rf', pre]
				subprocess.check_call(cmd)

			cmd = ['mkdir', pre]
			subprocess.check_call(cmd)
			
			#move coding alignments into _html
			cmd = ['mv', coding_alignments_dir, pre]
			subprocess.call(cmd)

			ucsc = open(pre+args.out_prefix+".overlap.bed", 'w')
			ucscSet = set()
			ucsc.write("track name=overlapping transcripts type=bed visibility=2\n")
		
		filtered = open(args.out_prefix+".filtered.txt", 'w')
		for x in SMALL_FILTER:
			filtered.write("%s\tless than 200 basepairs\n" % x[0])

		for x in SENSE_FILTER:
			filtered.write("%s\t%.1f%% exonic overlap with coding transcript %s in same orientation\n" % (x[0], x[2]*100.0, x[1]))
			if not args.no_web and x[0] not in ucscSet:
				ucsc.write(ogLncs[x[0]])
				ucscSet.add(x[0])
		for x in ANTISENSE_FILTER:
			filtered.write("%s\t%.1f%% exonic overlap with coding transcript %s in opposite orientation\n" % (x[0], x[2]*100.0, x[1]))
			if not args.no_web and  x[0] not in ucscSet:
				ucsc.write(ogLncs[x[0]])
				ucscSet.add(x[0])
		for x in WITHIN_FILTER:
			filtered.write("%s\ttranscript entirely within coding transcript %s\n" % (x[0], x[1]))
			if not args.no_web and  x[0] not in ucscSet:
				ucsc.write(ogLncs[x[0]])
				ucscSet.add(x[0])
		for x in SENSE_MAPPED_CODING_FILTER:
			filtered.write("%s\t%.1f%% exonic overlap with mapped coding transcript %s in same orientation\n" % (x[0], x[2]*100.0, x[1]))
			if not args.no_web and x[0] not in ucscSet:
				ucsc.write(ogLncs[x[0]])
				ucscSet.add(x[0])
		for x in ANTISENSE_MAPPED_CODING_FILTER:
			filtered.write("%s\t%.1f%% exonic overlap with mapped coding transcript %s in opposite orientation\n" % (x[0], x[2]*100.0, x[1]))
			if not args.no_web and x[0] not in ucscSet:
				ucsc.write(ogLncs[x[0]])
				ucscSet.add(x[0])
		
		#make bed files for alignment visualization
		if not args.no_web:
			blastToCodingLncs = set()
			blastToCodingCoding = set()
			blastToCodingLncBed = open(pre+coding_alignments_dir+args.assembly+".lincs.bed", 'w')
			blastToCodingCodingBed = open(pre+coding_alignments_dir+ANNOTS["ORTHOLOG"][0]+".coding.bed", 'w')

		for x in CODING_BLAST_FILTER:
			if not args.no_web:
				blastToCodingLncs.add(x[0])
				blastToCodingCoding.add(x[1])
			filtered.write("%s blasts to %s transcript %s with %0.1f%% exonic identity\n" % (x[0], ANNOTS["ORTHOLOG"][0], x[1], float(x[2])*100.0))
	
		if not args.no_web:
			for blastToCodingLnc in blastToCodingLncs:
				blastToCodingLncBed.write(ogLncs[blastToCodingLnc])
			for x in ORTH_ANNOTS["CODING"]:
				curCodingBed = open(x, 'r')
				while True:
					line = curCodingBed.readline()
					if line == "": break
					splitline = line.split()
					if splitline[3].strip() in blastToCodingCoding:
						blastToCodingCodingBed.write(line)
			blastToCodingLncBed.close()
			blastToCodingCodingBed.close()

			#tar
			null = open("/dev/null", 'w')
			cmd = ['tar', '-czvf', pre+coding_alignments_dir[0:-1]+".tar.gz", pre+coding_alignments_dir]
			subprocess.check_call(cmd, stdout = null, stderr = null)
			null.close()
			cmd = ['rm', '-rf', pre+coding_alignments_dir]
			subprocess.check_call(cmd)


		for x in SELF_BLAST_FILTER:
			filtered.write("%s blasts to %s with %0.1f%% identity and %0.1f%% coverage. Appears to be duplication.\n" % (x[0], x[1], float(x[2]), float(x[3])))
		for x in REPEAT_FILTER:
			filtered.write("%s has %.1f%% repeat content.  Appears to be mapping artifact.\n" % (x[0], x[1] * 100))
	#ORTH SEARCH
	if not args.no_orth_search:

		alignments_dir = args.out_prefix+"_alignments/"
		if not os.path.exists(alignments_dir):
			#cmd = ['mkdir', alignments_dir]
			#subprocess.check_call(cmd)
			os.mkdir(alignments_dir)
		lncBed = open(alignments_dir+args.assembly+".lincs.bed", 'w')
		orthBed = open(alignments_dir+ANNOTS["ORTHOLOG"][0]+".lincs.bed", 'w')


		if "NONCODING" in ORTH_ANNOTS and "LIFTOVER" in ANNOTS and "GENOME_FA" in ANNOTS and "GENOME_FA" in ORTH_ANNOTS:
			print "Searching for orthologs..."

			#load noncoding bed for later:
			noncodingBed = {}
			for annot_file in ORTH_ANNOTS["NONCODING"]:
				annot = open(annot_file, 'r')
				for line in annot:
					noncodingBed[line.split()[3].strip()] = line

			ORTHOLOGS = blastToOrtholog(lncs, ANNOTS, ORTH_ANNOTS, "NONCODING", args.noncoding_blast_min, args.threads, alignments_dir)
			tmpLncs, numRemoved = removeLncs(lncs, ORTHOLOGS)
			print "\r        ... %d transcripts with noncoding ortholog!                                                                                 \n" % numRemoved
			
			#categorize orthologs by annotation
			categorizeLncsByAnnots(ogLncs, ORTHOLOGS, ANNOTS)
			
			#get gene symbol
			if "GENESYMBOL" in ANNOTS or "GENESYMBOL" in ORTH_ANNOTS:
				geneSymbol(ogLncs, ORTHOLOGS, ANNOTS, ORTH_ANNOTS)	
		
		
			ORTHOLOGS.sort()
			#FILTER TOP ORTHOLOGS
			lncToOrtholog = {}
			for entry in ORTHOLOGS:
				if entry[0] not in lncToOrtholog: lncToOrtholog[entry[0]] = entry
				else:
					curExonId = lncToOrtholog[entry[0]][2]
					if entry[2] > curExonId: lncToOrtholog[entry[0]] = entry

			#WRITE ORTHOLOGS
			orthologs = open(args.out_prefix+".orthologs.txt", 'w')
			orthologs_top = open(args.out_prefix+".orthologs.top.txt", 'w')

			orthologs.write("#lnc\tlncGeneSymbol\tortholog\torthologGeneSymbol\texonID\tseqID\tcategory(alignment)\tcategory(annotation)\n")
			orthologs_top.write("#lnc\tlncGeneSymbol\tortholog\torthologGeneSymbol\texonID\tseqID\tcategory(alignment)\tcategory(annotation)\n")
		
			for entry in ORTHOLOGS:
				orthologs.write("%s\t%s\t%s\t%s\t%.2f\t%.2f\t%s\t%s\n" % (entry[0], entry[6], entry[1], entry[7], entry[2], entry[3], entry[4], entry[5]))
		
			for lnc,entry in lncToOrtholog.iteritems():
				orth = entry[1]
				lncBedEntry = ogLncs[lnc]
				orthBedEntry = noncodingBed[orth]
				
				lncBed.write(lncBedEntry)
				orthBed.write(orthBedEntry)
				orthologs_top.write("%s\t%s\t%s\t%s\t%.2f\t%.2f\t%s\t%s\n" % (entry[0], entry[6], entry[1], entry[7], entry[2], entry[3], entry[4], entry[5]))
			lncBed.close()
			orthBed.close()
		
			null = open("/dev/null", 'w')
			cmd = ['tar', '-czvf', alignments_dir[0:-1]+".tar.gz", alignments_dir]
			subprocess.check_call(cmd, stdout=null, stderr=null)
			cmd = ['rm', '-rf', alignments_dir]
			subprocess.check_call(cmd)

		else:
			print "Not enough information to search for orthologs! Please check you have genome fastas for both species, a liftOver file, and an ortholog noncoding file specificied in your annotations.config"

	#WRITE WEBSITE
	pre = args.out_prefix+"_html/"

	if not args.no_web: 
		if not args.no_filter:
			writeWebsite(ANNOTS, args.out_prefix, ogLncs, args.sense_min, args.antisense_min, args.coding_blast_min, SENSE_FILTER, ANTISENSE_FILTER, SENSE_MAPPED_CODING_FILTER, ANTISENSE_MAPPED_CODING_FILTER, CODING_BLAST_FILTER, SELF_BLAST_FILTER, args.selfblast_identity_min, REPEAT_FILTER, REPEAT_CONTENT, args.repeat_min, lncs)
		else:
			writeNoFilterWebsite(args.out_prefix)
		if not args.no_orth_search:
			writeOrthSearch(args.out_prefix, args.noncoding_blast_min, ORTHOLOGS)
		else:
			writeNoOrthSearch(args.out_prefix)

if __name__ == "__main__":
	main()
